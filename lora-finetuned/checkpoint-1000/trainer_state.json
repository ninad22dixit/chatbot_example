{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 8.806955337524414,
      "learning_rate": 0.00019820000000000002,
      "loss": 3.4812,
      "step": 10
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33269959688186646,
      "learning_rate": 0.0001962,
      "loss": 0.2798,
      "step": 20
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.27481111884117126,
      "learning_rate": 0.0001942,
      "loss": 0.1801,
      "step": 30
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.15563219785690308,
      "learning_rate": 0.0001922,
      "loss": 0.1337,
      "step": 40
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.2626408636569977,
      "learning_rate": 0.0001902,
      "loss": 0.1481,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.23997443914413452,
      "learning_rate": 0.0001882,
      "loss": 0.1227,
      "step": 60
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.2127111852169037,
      "learning_rate": 0.00018620000000000003,
      "loss": 0.126,
      "step": 70
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.16003017127513885,
      "learning_rate": 0.0001842,
      "loss": 0.1183,
      "step": 80
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.25313377380371094,
      "learning_rate": 0.0001822,
      "loss": 0.1205,
      "step": 90
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.33223915100097656,
      "learning_rate": 0.00018020000000000002,
      "loss": 0.1036,
      "step": 100
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.1885303556919098,
      "learning_rate": 0.00017820000000000002,
      "loss": 0.1219,
      "step": 110
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.23608753085136414,
      "learning_rate": 0.0001762,
      "loss": 0.1179,
      "step": 120
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.2133953720331192,
      "learning_rate": 0.0001742,
      "loss": 0.1104,
      "step": 130
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2071997970342636,
      "learning_rate": 0.0001722,
      "loss": 0.093,
      "step": 140
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2536061108112335,
      "learning_rate": 0.00017020000000000002,
      "loss": 0.1079,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.3305913805961609,
      "learning_rate": 0.0001682,
      "loss": 0.1123,
      "step": 160
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3157919645309448,
      "learning_rate": 0.0001662,
      "loss": 0.101,
      "step": 170
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1945521980524063,
      "learning_rate": 0.0001642,
      "loss": 0.0956,
      "step": 180
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.2856195271015167,
      "learning_rate": 0.0001622,
      "loss": 0.1079,
      "step": 190
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.21943679451942444,
      "learning_rate": 0.00016020000000000002,
      "loss": 0.0951,
      "step": 200
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.186663419008255,
      "learning_rate": 0.00015820000000000002,
      "loss": 0.0984,
      "step": 210
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.2772533893585205,
      "learning_rate": 0.0001562,
      "loss": 0.1025,
      "step": 220
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.16824890673160553,
      "learning_rate": 0.0001542,
      "loss": 0.1015,
      "step": 230
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2470056563615799,
      "learning_rate": 0.0001522,
      "loss": 0.1193,
      "step": 240
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.24350328743457794,
      "learning_rate": 0.00015020000000000002,
      "loss": 0.0964,
      "step": 250
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2945326864719391,
      "learning_rate": 0.0001482,
      "loss": 0.1114,
      "step": 260
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.21325846016407013,
      "learning_rate": 0.0001462,
      "loss": 0.0919,
      "step": 270
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.26290425658226013,
      "learning_rate": 0.0001442,
      "loss": 0.0968,
      "step": 280
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2606043219566345,
      "learning_rate": 0.0001422,
      "loss": 0.1047,
      "step": 290
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2683376967906952,
      "learning_rate": 0.0001402,
      "loss": 0.0896,
      "step": 300
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.18875817954540253,
      "learning_rate": 0.0001382,
      "loss": 0.0856,
      "step": 310
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.22020988166332245,
      "learning_rate": 0.0001362,
      "loss": 0.1033,
      "step": 320
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.18606121838092804,
      "learning_rate": 0.0001342,
      "loss": 0.1088,
      "step": 330
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.2598724365234375,
      "learning_rate": 0.00013220000000000001,
      "loss": 0.1022,
      "step": 340
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.27969884872436523,
      "learning_rate": 0.00013020000000000002,
      "loss": 0.1063,
      "step": 350
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1805141568183899,
      "learning_rate": 0.0001282,
      "loss": 0.11,
      "step": 360
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.2331860363483429,
      "learning_rate": 0.0001262,
      "loss": 0.1012,
      "step": 370
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.3054615557193756,
      "learning_rate": 0.0001242,
      "loss": 0.0916,
      "step": 380
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.32900089025497437,
      "learning_rate": 0.00012220000000000002,
      "loss": 0.1094,
      "step": 390
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20183232426643372,
      "learning_rate": 0.00012020000000000001,
      "loss": 0.0904,
      "step": 400
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2721794545650482,
      "learning_rate": 0.0001182,
      "loss": 0.1044,
      "step": 410
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.29070788621902466,
      "learning_rate": 0.00011619999999999999,
      "loss": 0.1092,
      "step": 420
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.20882563292980194,
      "learning_rate": 0.0001142,
      "loss": 0.1029,
      "step": 430
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2253260463476181,
      "learning_rate": 0.00011220000000000002,
      "loss": 0.0908,
      "step": 440
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.35971978306770325,
      "learning_rate": 0.00011020000000000001,
      "loss": 0.0825,
      "step": 450
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.2608717381954193,
      "learning_rate": 0.00010820000000000001,
      "loss": 0.0969,
      "step": 460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.22829608619213104,
      "learning_rate": 0.0001062,
      "loss": 0.1122,
      "step": 470
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2745004892349243,
      "learning_rate": 0.00010420000000000001,
      "loss": 0.1028,
      "step": 480
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.19406983256340027,
      "learning_rate": 0.0001022,
      "loss": 0.0964,
      "step": 490
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.22495248913764954,
      "learning_rate": 0.00010020000000000001,
      "loss": 0.0998,
      "step": 500
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.2682379484176636,
      "learning_rate": 9.82e-05,
      "loss": 0.0959,
      "step": 510
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.24960771203041077,
      "learning_rate": 9.620000000000001e-05,
      "loss": 0.091,
      "step": 520
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.2486874759197235,
      "learning_rate": 9.42e-05,
      "loss": 0.0812,
      "step": 530
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.23435281217098236,
      "learning_rate": 9.22e-05,
      "loss": 0.0985,
      "step": 540
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.2115781307220459,
      "learning_rate": 9.020000000000001e-05,
      "loss": 0.0967,
      "step": 550
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.17904983460903168,
      "learning_rate": 8.82e-05,
      "loss": 0.089,
      "step": 560
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.29431644082069397,
      "learning_rate": 8.620000000000001e-05,
      "loss": 0.0953,
      "step": 570
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.1769746094942093,
      "learning_rate": 8.42e-05,
      "loss": 0.1226,
      "step": 580
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.2669839560985565,
      "learning_rate": 8.22e-05,
      "loss": 0.1034,
      "step": 590
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.229757159948349,
      "learning_rate": 8.020000000000001e-05,
      "loss": 0.0989,
      "step": 600
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.19910433888435364,
      "learning_rate": 7.82e-05,
      "loss": 0.0966,
      "step": 610
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.27312278747558594,
      "learning_rate": 7.620000000000001e-05,
      "loss": 0.0937,
      "step": 620
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.2851513624191284,
      "learning_rate": 7.42e-05,
      "loss": 0.1072,
      "step": 630
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.350159615278244,
      "learning_rate": 7.22e-05,
      "loss": 0.0984,
      "step": 640
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.22373703122138977,
      "learning_rate": 7.02e-05,
      "loss": 0.0957,
      "step": 650
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.3261147737503052,
      "learning_rate": 6.82e-05,
      "loss": 0.0923,
      "step": 660
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3186148405075073,
      "learning_rate": 6.620000000000001e-05,
      "loss": 0.1097,
      "step": 670
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2526933550834656,
      "learning_rate": 6.42e-05,
      "loss": 0.1037,
      "step": 680
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3525557219982147,
      "learning_rate": 6.220000000000001e-05,
      "loss": 0.0982,
      "step": 690
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.2879641056060791,
      "learning_rate": 6.02e-05,
      "loss": 0.0853,
      "step": 700
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.23738618195056915,
      "learning_rate": 5.82e-05,
      "loss": 0.0976,
      "step": 710
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.2441071718931198,
      "learning_rate": 5.620000000000001e-05,
      "loss": 0.0967,
      "step": 720
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.20146703720092773,
      "learning_rate": 5.420000000000001e-05,
      "loss": 0.0844,
      "step": 730
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.28397318720817566,
      "learning_rate": 5.22e-05,
      "loss": 0.0941,
      "step": 740
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.2641146779060364,
      "learning_rate": 5.02e-05,
      "loss": 0.0919,
      "step": 750
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.32925745844841003,
      "learning_rate": 4.82e-05,
      "loss": 0.0878,
      "step": 760
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.26731857657432556,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0944,
      "step": 770
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.34483572840690613,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.111,
      "step": 780
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.3188149929046631,
      "learning_rate": 4.22e-05,
      "loss": 0.1032,
      "step": 790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.19923926889896393,
      "learning_rate": 4.02e-05,
      "loss": 0.0986,
      "step": 800
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.2407110184431076,
      "learning_rate": 3.82e-05,
      "loss": 0.1054,
      "step": 810
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.21250471472740173,
      "learning_rate": 3.62e-05,
      "loss": 0.1089,
      "step": 820
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.2999301254749298,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0941,
      "step": 830
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3122994899749756,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.096,
      "step": 840
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.17609736323356628,
      "learning_rate": 3.02e-05,
      "loss": 0.0992,
      "step": 850
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.2517363727092743,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.1013,
      "step": 860
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.21987780928611755,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.098,
      "step": 870
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2575112581253052,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.1033,
      "step": 880
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.20145584642887115,
      "learning_rate": 2.22e-05,
      "loss": 0.0838,
      "step": 890
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.3445955216884613,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.1066,
      "step": 900
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.27556660771369934,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0982,
      "step": 910
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.26425671577453613,
      "learning_rate": 1.62e-05,
      "loss": 0.1027,
      "step": 920
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.308386892080307,
      "learning_rate": 1.42e-05,
      "loss": 0.1007,
      "step": 930
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2187577784061432,
      "learning_rate": 1.22e-05,
      "loss": 0.1097,
      "step": 940
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.20804059505462646,
      "learning_rate": 1.02e-05,
      "loss": 0.103,
      "step": 950
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.1694580614566803,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.079,
      "step": 960
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.250302255153656,
      "learning_rate": 6.2e-06,
      "loss": 0.086,
      "step": 970
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.19212564826011658,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0805,
      "step": 980
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.252951979637146,
      "learning_rate": 2.2e-06,
      "loss": 0.0996,
      "step": 990
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.18459036946296692,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.1015,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6362964688896000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
